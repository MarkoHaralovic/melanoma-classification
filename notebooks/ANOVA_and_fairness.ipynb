{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f73e322",
   "metadata": {},
   "source": [
    "# Fairness estimation with ANOVA\n",
    "\n",
    "We want to test whether or not our models output equally high malignancy probabilities $P(y=\\text{malignant} \\mid x)$ across skin color groups.\n",
    "\n",
    "We'll perform this analysis on the outputs of our three best experiments to assess their fairness and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed0d076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c25bc0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6562,), (6562,), (6562, 3))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "root_dir = \"C:\\\\Users\\\\Duje\\\\Desktop\\\\fer\\\\8. semestar\\\\lumen\\\\rezultati\\\\02 eksperimenti\\\\\"\n",
    "experiments = [\n",
    "    \"10 transformer\\\\normal\", \n",
    "    \"12 domain discriminative\\\\new\", \n",
    "    \"16 efficient m\\\\new\",\n",
    "]\n",
    "\n",
    "y_true = []\n",
    "groups = []\n",
    "y_prob = []\n",
    "\n",
    "for exp in experiments:\n",
    "    eval_dir = os.path.join(root_dir, exp, \"eval\")\n",
    "    y_true.append(np.load(os.path.join(eval_dir, \"best_model\", \"y_true.npy\")))\n",
    "    groups.append(np.load(os.path.join(eval_dir, \"best_model\", \"groups.npy\")))\n",
    "\n",
    "    # We only need the post. prob. of the malignant class\n",
    "    p = np.load(os.path.join(eval_dir, \"best_model\", \"probs.npy\"))\n",
    "    y_prob.append(p[:, 1])\n",
    "\n",
    "\n",
    "# We know that that y_true and groups are the same across experiments\n",
    "assert (y_true[0] == y_true[1]).all() and (y_true[1] == y_true[2]).all()\n",
    "assert (groups[0] == groups[1]).all() and (groups[1] == groups[2]).all()\n",
    "y_true = y_true[0]\n",
    "groups = groups[0]\n",
    "\n",
    "# One column for each model\n",
    "y_prob = np.stack(y_prob, axis=1)\n",
    "\n",
    "y_true.shape, groups.shape, y_prob.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6db355",
   "metadata": {},
   "source": [
    "## Positive subset\n",
    "\n",
    "We want to test if the trained models behave differently across skin color groups on GT malignant samples, regardless of whether or not they were correctly labeled by the model.\n",
    "\n",
    "This gives us an overall view of the fairness of each model and checks for confidece disparities in all malignant samples. \n",
    "\n",
    "- $H_0$ - Mean probabilities $P(y=\\text{malignant} \\mid x)$ are equal for GT malignant samples across all skin color groups\n",
    "- $H_1$ - At least one mean probability is different than the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71717145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17, 3), (58, 3), (46, 3), (16, 3))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_0 = y_prob[np.logical_and(y_true == 1, groups == 0), :]\n",
    "group_1 = y_prob[np.logical_and(y_true == 1, groups == 1), :]\n",
    "group_2 = y_prob[np.logical_and(y_true == 1, groups == 2), :]\n",
    "group_3 = y_prob[np.logical_and(y_true == 1, groups == 3), :]\n",
    "\n",
    "group_0.shape, group_1.shape, group_2.shape, group_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ddba0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tExp 1\t\tExp 2\t\tExp 3\n",
      "Group 0\t\t83.81 +- 32.31\t32.04 +- 27.95\t78.38 +- 33.42\n",
      "Group 1\t\t50.82 +- 41.04\t22.96 +- 27.22\t43.50 +- 41.02\n",
      "Group 2\t\t65.81 +- 37.61\t25.08 +- 25.30\t58.08 +- 40.39\n",
      "Group 3\t\t73.51 +- 28.47\t26.05 +- 22.27\t65.32 +- 36.11\n"
     ]
    }
   ],
   "source": [
    "# Mean and std values\n",
    "all_groups = [group_0, group_1, group_2, group_3]\n",
    "\n",
    "print(\"\\t\\tExp 1\\t\\tExp 2\\t\\tExp 3\")\n",
    "for i, group in enumerate(all_groups):\n",
    "    print(f\"Group {i}\", end='\\t')\n",
    "    mean = np.mean(group, axis=0)\n",
    "    std = np.std(group, axis=0)\n",
    "    for m, s in zip(mean, std):\n",
    "        print(f\"\\t{100*m:.2f} +- {100*s:.2f}\", end=\"\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "443c8d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.14200588, 0.52022699, 3.98315294]),\n",
       " array([0.00764976, 0.6690862 , 0.00937104]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F = f_oneway(group_0, group_1, group_2, group_3)\n",
    "F.statistic, F.pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771ccaef",
   "metadata": {},
   "source": [
    "$\\implies$ We can discard $H_0$ with a $0.05$ level of significance in experimets 1 and 3.\n",
    "\n",
    "This indicates the presence of skin-color bias in those two models; more specifically that those models are not equally confident in their decisions across groups. Looking at the mean values per group, models 1 and 3 seem to give more opportunities (higher confidence) to the minority skin groups. However, knowing that group 1 had the majority in the training data, we can safely assume that the results on other groups are overly optimistic.\n",
    "\n",
    "The mean values for experiment 2 suggest a very stable condifence across skin color groups, dispite the fact that the training data was highly imbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5ae341",
   "metadata": {},
   "source": [
    "## True positive subset\n",
    "\n",
    "Looking only at the samples that were correctly labeled as malignant, we can check if our model was less confident to assign that label on different skin color groups. \n",
    "\n",
    "- $H_0$ - Mean probabilities $P(y=\\text{malignant} \\mid x)$ are equal for correcty classified samples across all skin color groups\n",
    "- $H_1$ - At least one mean probability is different than the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64aa028a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1:\n",
      "\tGroup 0\t  94.96 +- 11.24\n",
      "\tGroup 1\t  87.85 +- 15.83\n",
      "\tGroup 2\t  88.52 +- 14.83\n",
      "\tGroup 3\t  82.72 +- 15.69\n",
      "Experiment 2:\n",
      "\tGroup 0\t  65.02 +- 4.85\n",
      "\tGroup 1\t  63.94 +- 4.66\n",
      "\tGroup 2\t  63.91 +- 4.80\n",
      "\tGroup 3\t  62.77 +- 6.90\n",
      "Experiment 3:\n",
      "\tGroup 0\t  92.96 +- 12.04\n",
      "\tGroup 1\t  86.54 +- 15.73\n",
      "\tGroup 2\t  90.26 +- 11.82\n",
      "\tGroup 3\t  88.05 +- 13.36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.61153694, 0.13112771, 0.74056832]),\n",
       " array([0.19251901, 0.94083616, 0.53122427]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of TPs varies between experiments\n",
    "stats = []\n",
    "pvals = []\n",
    "\n",
    "for exp in range(len(experiments)):\n",
    "    print(f\"Experiment {exp+1}:\")\n",
    "    group_0 = y_prob[np.logical_and(y_true == 1, groups == 0), exp]\n",
    "    group_1 = y_prob[np.logical_and(y_true == 1, groups == 1), exp]\n",
    "    group_2 = y_prob[np.logical_and(y_true == 1, groups == 2), exp]\n",
    "    group_3 = y_prob[np.logical_and(y_true == 1, groups == 3), exp]\n",
    "    \n",
    "    group_0 = group_0[group_0 > 0.5]\n",
    "    group_1 = group_1[group_1 > 0.5]\n",
    "    group_2 = group_2[group_2 > 0.5]\n",
    "    group_3 = group_3[group_3 > 0.5]\n",
    "\n",
    "    all_groups = [group_0, group_1, group_2, group_3]\n",
    "\n",
    "    for i, group in enumerate(all_groups):\n",
    "        print(f\"\\tGroup {i}\", end='\\t')\n",
    "        mean = np.mean(group)\n",
    "        std = np.std(group)\n",
    "        print(f\"  {100*mean:.2f} +- {100*std:.2f}\", end=\"\")\n",
    "        print()\n",
    "\n",
    "    F = f_oneway(group_0, group_1, group_2, group_3)\n",
    "    stats.append(F.statistic)\n",
    "    pvals.append(F.pvalue)\n",
    "\n",
    "np.array(stats), np.array(pvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0320652c",
   "metadata": {},
   "source": [
    "$\\implies$ We fail to reject the null hypothesis in all three experiments.\n",
    "\n",
    "When only considering true positive predictions, we see no statistically significant evidence of confidence disparities. \n",
    "\n",
    "Unlike the results of the previous ANOVA analysis, this analysis did not reveal any biases in experiments 1 and 3. This further shows that, when only looking at TP samples, we have a slighlty biased and less general view of our model's fairness. Thus, we suspect that the models in experiments 1 and 3 could be fair (consistently confident) in the cases that they are correct, but they do in general show some bias. However, this does not seem to be the case for the model in experiment 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
