\chapter{Environment Setup}
\label{ch:env_setup}

We ensured our code works reliably by using Conda environments. We separated dependencies into:
device-specific packages (e.g., \texttt{torch}, \texttt{torchaudio}), development dependencies (e.g., \texttt{isort}, \texttt{black}), and core library requirements.

This approach was further extended using Docker to containerize our code. We created two Dockerfiles—one for GPU and one for CPU execution—depending on the availability of a CUDA-capable device. This separation of concerns was motivated by the fact that, as a two-member team with different hardware, we wanted to avoid creating custom Dockerfiles for each user. The only user-specific setting that needs to be changed is the CUDA version.

Our environment can be created by:
\begin{enumerate}
    \item Using Conda and the \texttt{environment.yaml} dependency file.
    \item Using Conda and following the instructions in \texttt{INSTALL.md}.
    \item Building a GPU or CPU Docker image.
    \item Pulling the prebuilt GPU or CPU Docker image from Docker Hub.
\end{enumerate}

In the following sections, we provide detailed instructions on setting up the environment.

\section{Conda install using environment YAML file} 

On the main branch of the code, in the root directory, you can find the environment.yml file. The only prerequisite is to have Conda installed, and the environment can be recreated with a single line of code. However, within that YAML file, the user must specify the correct versions of dependencies based on the CUDA and cuDNN versions being used.

\begin{lstlisting}[language=bash, caption={Creating Conda environment from \texttt{environment.yml}}, label=list:create_conda_env]
           conda env create -f environment.yml
\end{lstlisting}

\section{Conda install following the instructions from INSTALL.md}\label{subsec:reflinks}
For a more controled approach, follow these instructions:

\begin{lstlisting}[language=bash, caption={Environment setup using Conda and pip}, label=list:full_env_setup]
# Create and activate Conda environment
conda create -n melanoma python=3.10 -y
conda activate melanoma

# Install dependencies from requirements file
pip install -r requirements.txt

# For CPU-only installation of PyTorch and related libraries:
pip install \
   torch==2.2.0+cpu \
   torchvision==0.17.0+cpu \
   torchaudio==2.2.0+cpu \
   -f https://download.pytorch.org/whl/cpu/torch_stable.html
\end{lstlisting}

\noindent
\textbf{Note:} If you are using a GPU, make sure to install the appropriate version of PyTorch that matches your CUDA version.  
You can find the correct installation command for your system on the official \href{https://pytorch.org/get-started/locally/}{PyTorch website}.


\section{Docker installation}
To build and run the project using Docker, follow the instructions below depending on whether you are using a CPU or a GPU.

\subsection*{CPU Setup}
Place yourself in the project’s root directory and run the following commands:

\begin{lstlisting}[language=bash, caption={Build and run Docker container (CPU version)}, label=list:docker_cpu]
# Build the Docker image using the CPU Dockerfile
docker build -t melanoma -f docker/Dockerfile_cpu .

# Run the Docker container interactively
docker run -it melanoma
\end{lstlisting}

\subsection*{GPU Setup}
If you have a CUDA-compatible GPU and NVIDIA Docker runtime installed, use the GPU-specific Dockerfile:

\begin{lstlisting}[language=bash, caption={Build and run Docker container (GPU version)}]
# Build the Docker image using the GPU Dockerfile
docker build -t melanoma -f docker/Dockerfile .

# Run the Docker container interactively
docker run -it --gpus all melanoma
\end{lstlisting}



\section{Pull prebuilt image from Docker Hub}
If you prefer not to build the image locally, you can pull the latest version from Docker Hub. We pushed already buitl images there, both for CPU and GPU devices. 

\begin{lstlisting}[language=bash, caption={Pull and run the Docker image from Docker Hub}, label=list:docker_hub]
# Pull the CPU image from Docker Hub
docker pull haralovicmarko/melanoma_cpu:latest

# Run the container (CPU version)
docker run -it haralovicmarko/melanoma_cpu:latest

# Run the container (CPU version) with mounted dir (of images and weights for example)
docker run -it \
  -v /path/to/local/data:/melanoma-classification/data \
  -v /path/to/local/weights:/melanoma-classification/weights \
  haralovicmarko/melanoma_cpu:latest

# Pull the GPU image from Docker Hub
docker pull haralovicmarko/melanoma_gpu:latest

# Run with GPU support 
docker run -it --gpus all haralovicmarko_gpu/melanoma_cpu:latest

# Run with GPU support and mounted directories (again for weights and images dir)
docker run -it --gpus all \
  -v /path/to/local/data:/melanoma-classification/data \
  -v /path/to/local/weights:/melanoma-classification/weights \
  haralovicmarko/melanoma_gpu:latest
  
\end{lstlisting}
